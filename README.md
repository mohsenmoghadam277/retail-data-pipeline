# ğŸš€ Retail Real-Time Data Pipeline

## ğŸ“Œ Overview
This repository contains an **end-to-end real-time data engineering pipeline** designed for retail sales analytics.  
The project demonstrates how streaming sales data can be ingested, processed, stored, and exposed for analytical and BI use cases.

This project is built to reflect **real-world Data Engineering workflows**, not just dashboarding.

---

## ğŸ§  Architecture
Data Producer
â†“
Apache Kafka
â†“
Apache Spark (Structured Streaming)
â†“
PostgreSQL (Analytical Storage)
â†“
Metabase (BI & Analytics)

---

## ğŸ§± Tech Stack
- Python
- Apache Kafka
- Apache Spark (Structured Streaming)
- PostgreSQL
- Metabase
- Docker & Docker Compose

---

## ğŸ“‚ Project Structure
retail-data-pipeline/
â”œâ”€â”€ producer/
â”‚ â””â”€â”€ sales_producer.py
â”œâ”€â”€ spark-jobs/
â”‚ â””â”€â”€ sales_stream_processor.py
â”œâ”€â”€ sql/
â”‚ â”œâ”€â”€ schema.sql
â”‚ â””â”€â”€ indexes.sql
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## ğŸ”„ Data Flow
1. **Data Ingestion**  
   Simulated retail sales events are produced and published to Kafka topics.

2. **Stream Processing**  
   Spark Structured Streaming consumes data from Kafka and applies:
   - Schema validation
   - Data cleaning (null handling, deduplication)
   - Aggregations (revenue, daily sales)

3. **Data Storage**  
   Processed data is stored in PostgreSQL using an analytical-friendly schema.

4. **Analytics Layer**  
   Metabase connects to PostgreSQL to provide dashboards and business insights.

---

## ğŸ—„ï¸ Data Model
### Fact Table
- `fact_sales`
  - sale_id
  - product_id
  - quantity
  - total_price
  - sale_timestamp

### Dimension Tables
- `dim_product`
- `dim_date`

The model follows **star schema principles** for efficient analytical queries.

---

## â–¶ï¸ How to Run
```bash
docker-compose up -d
Steps:

Start Kafka, Spark, PostgreSQL services

Run the Kafka producer

Execute the Spark streaming job

Access Metabase via browser

ğŸ“Š Sample Analytics

Total revenue per day

Top-selling products

Real-time transaction volume

Sales trends over time

ğŸ” Key Concepts Demonstrated

Real-time data ingestion

Stream processing with Spark

Data cleaning & validation

Analytical data modeling

Scalable data pipeline design

BI-ready data delivery

ğŸ¯ Why This Project

This project showcases Data Engineering fundamentals commonly required in production environments and bridges the gap between raw streaming data and business intelligence systems.

ğŸ‘¤ Author

Mohsen Moghadam
Data Engineer | BI Lead | Backend Developer
ğŸ“§ mohsenmoghadam277@gmail.com

ğŸ”— GitHub: https://github.com/mohsenmoghadam277
